name: Deploy to S3

on:
  push:
    branches:
      - main
  workflow_dispatch:

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Build application
        run: npm run build
        env:
          # Add your environment variables here
          VITE_SUPABASE_URL: ${{ secrets.VITE_SUPABASE_URL }}
          VITE_SUPABASE_ANON_KEY: ${{ secrets.VITE_SUPABASE_ANON_KEY }}
          VITE_AUTH0_DOMAIN: ${{ secrets.VITE_AUTH0_DOMAIN }}
          VITE_AUTH0_CLIENT_ID: ${{ secrets.VITE_AUTH0_CLIENT_ID }}
          VITE_AUTH0_AUDIENCE: ${{ secrets.VITE_AUTH0_AUDIENCE }}

      - name: List build output
        run: |
          echo "Contents of dist folder:"
          ls -R dist/

      - name: Summarize build size
        run: |
          echo "Dist total size:" 
          du -sh dist || true
          echo "Top-level dist files:" 
          ls -alh dist || true
          echo "All files with sizes:" 
          find dist -maxdepth 3 -type f -exec ls -alh {} \; || true

      - name: Upload dist artifact
        uses: actions/upload-artifact@v4
        with:
          name: dist-${{ github.run_number }}
          path: dist
          if-no-files-found: error
          retention-days: 7

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Deploy to S3
        run: |
          echo "Syncing files to S3..."
          aws s3 sync dist/ s3://${{ secrets.S3_BUCKET_NAME }}/ --delete
          echo "Deployment complete!"
          echo "Listing S3 bucket contents:"
          aws s3 ls s3://${{ secrets.S3_BUCKET_NAME }}/ --recursive
          
      # Re-upload with proper cache headers while preserving content-type (aws assigns by extension on upload).
      - name: Apply cache headers (assets & HTML)
        run: |
          echo "Uploading versioned assets with long cache headers..."
          aws s3 cp dist/ s3://${{ secrets.S3_BUCKET_NAME }}/ --recursive --exclude "index.html" --cache-control "max-age=31536000,public"
          echo "Uploading index.html with no-cache headers..."
          aws s3 cp dist/index.html s3://${{ secrets.S3_BUCKET_NAME }}/index.html --cache-control "max-age=0,no-cache,no-store,must-revalidate" --content-type "text/html"
          echo "Verifying content-type of JS bundle:"
          JS_FILE=$(aws s3 ls s3://${{ secrets.S3_BUCKET_NAME }}/assets/ | awk '{print $4}' | grep -E '\.js$' | head -1)
          if [ -n "$JS_FILE" ]; then
            aws s3api head-object --bucket ${{ secrets.S3_BUCKET_NAME }} --key assets/$JS_FILE --query 'ContentType'
          else
            echo "No JS file found in assets directory"
          fi

      - name: Invalidate CloudFront cache (optional)
        if: vars.CLOUDFRONT_DISTRIBUTION_ID != ''
        run: |
          aws cloudfront create-invalidation --distribution-id ${{ vars.CLOUDFRONT_DISTRIBUTION_ID }} --paths "/*"
